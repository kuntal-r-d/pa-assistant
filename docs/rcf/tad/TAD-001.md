# Technical Architecture Document: TAD-001

## Zero-Cost Remote Job Search Automation System

| Metadata | Value |
|----------|-------|
| **TAD ID** | TAD-001 |
| **PRD ID** | PRD-001 |
| **Version** | 1.0.2 |
| **Status** | Draft |
| **Created** | 2026-02-08 |
| **Requirements Analyzed** | 49 functional + 8 non-functional |
| **User Stories Analyzed** | 297 |
| **Acceptance Criteria Analyzed** | 1,406 |

---

## Table of Contents

1. [Executive Summary](#1-executive-summary)
2. [System Overview](#2-system-overview)
3. [Architecture Principles](#3-architecture-principles)
4. [Component Architecture](#4-component-architecture)
5. [Data Architecture](#5-data-architecture)
6. [Integration Architecture](#6-integration-architecture)
7. [Security Architecture](#7-security-architecture)
8. [Deployment Architecture](#8-deployment-architecture)
9. [Operational Concerns](#9-operational-concerns)
10. [Architectural Decisions](#10-architectural-decisions)
11. [Multi-Agent Review Summary](#11-multi-agent-review-summary)

---

## 1. Executive Summary

A privacy-first, containerized job search automation system that eliminates manual effort while keeping all personal data local. The system uses a modular monolith architecture with specialized components for scraping, AI processing, and workflow automation.

### Problem Statement

Remote job seekers waste 15-20 hours/week manually searching across fragmented platforms, resulting in:
- 80% of relevant jobs being missed
- 2-5% response rates from generic applications
- 30% of applications lost due to poor tracking
- Cloud solutions cost $136/month, making them inaccessible for cost-conscious seekers

### Key Capabilities

- Multi-platform job scraping with anti-detection stealth technology
- AI-powered job-candidate matching with skill gap analysis
- Automated cover letter and CV generation using hybrid local/cloud AI
- Complete application lifecycle tracking with Kanban visualization
- Email integration for LinkedIn alerts and automated reporting
- Analytics dashboard with performance metrics and insights

### Target Users

- Remote job seekers (software developers, tech professionals)
- Career changers looking for remote opportunities
- Freelancers seeking full-time remote positions
- International candidates targeting US/UK/EU remote jobs

---

## 2. System Overview

### System Purpose

Automate the entire remote job search process from discovery to application tracking while maintaining zero infrastructure costs and complete data privacy through local-only deployment.

### Architectural Approach

Containerized modular monolith with specialized service components, orchestrated via Docker Compose for single-command deployment and managed through n8n workflow automation.

### Context Diagram

```
┌─────────────┐     ┌─────────────────────────────┐     ┌─────────────────┐
│   Remote    │────▶│    Job Search Automation    │────▶│   Job Boards    │
│ Job Seeker  │     │         System              │     │  (LinkedIn,     │
│             │◀────│                             │     │  RemoteOK, etc) │
└─────────────┘     │  ┌─────────┬─────────────┐  │     └─────────────────┘
                    │  │   Web   │   n8n       │  │              ▲
                    │  │Frontend │ Workflows   │  │              │
                    │  └─────────┴─────────────┘  │              │
                    │  ┌─────────┬─────────────┐  │              │
                    │  │Scraper  │ PostgreSQL  │  │              │
                    │  │   API   │  Database   │  │              │
                    │  └─────────┴─────────────┘  │              │
                    │  ┌─────────┬─────────────┐  │              │
                    │  │ Ollama  │   Email     │  │              │
                    │  │Local LLM│  Service    │  │              │
                    │  └─────────┴─────────────┘  │              │
                    └─────────────────────────────┘              │
                              │                                  │
                              ▼                                  │
                    ┌─────────────────┐                         │
                    │  Claude API     │─────────────────────────┘
                    │  (Optional)     │
                    └─────────────────┘
```

### External Dependencies

| System | Purpose | Protocol | Owner |
|--------|---------|----------|-------|
| LinkedIn Platform | Job scraping and email alert processing | HTTPS/Browser Automation | LinkedIn Corporation |
| RemoteOK API | Remote job listings aggregation | REST | RemoteOK |
| WeWorkRemotely | Remote job listings scraping | HTTP | WeWorkRemotely |
| Claude API (Anthropic) | High-quality content generation | HTTPS/REST | Anthropic |
| Email Service | LinkedIn alert processing and report delivery | SMTP/IMAP | User's email provider |
| Google Drive | Optional backup storage via rclone | HTTPS/OAuth | Google |

### Assumptions and Constraints

- Single user deployment with 8GB RAM minimum requirement
- Zero infrastructure cost constraint limits to local deployment only
- LinkedIn anti-bot protection requires sophisticated stealth techniques
- Legal compliance requires respecting Terms of Service for all job boards
- Privacy-first approach mandates all personal data remains local
- AI budget limited to $5/month for optional Claude API usage
- Docker environment available for containerized deployment

---

## 3. Architecture Principles

### 3.1 Privacy-by-Design

**Description:** All personal data, job applications, and user preferences must remain on the user's local machine with no external transmission except for explicitly configured optional services.

**Rationale:** Core value proposition is data privacy and zero-cost operation, distinguishing from expensive cloud solutions.

**Implications:**
- PostgreSQL database runs locally in container
- No user authentication or session management required
- API keys stored only in environment variables
- Optional cloud services (Claude API) require explicit user consent

### 3.2 Stealth-First Automation

**Description:** All automated interactions with external platforms must mimic human behavior to avoid detection and blocking.

**Rationale:** LinkedIn and other platforms actively block automated scrapers, requiring sophisticated anti-detection measures.

**Implications:**
- Browser fingerprint randomization for each session
- Human-like timing patterns with random delays
- Canvas and WebGL manipulation to avoid detection
- Circuit breakers and rate limiting to prevent suspicious patterns

### 3.3 Hybrid AI Strategy

**Description:** Combine local open-source models with optional premium APIs to balance cost, privacy, and quality.

**Rationale:** Provides flexibility between zero-cost local processing and high-quality cloud AI within budget constraints.

**Implications:**
- Ollama runs locally for basic AI tasks and fallback processing
- Claude API used optionally for premium content generation
- Graceful degradation when cloud services unavailable
- Cost monitoring to stay within $5/month budget

### 3.4 Single-Command Deployment

**Description:** Entire system must start with a single docker-compose command with minimal configuration required.

**Rationale:** Target users are job seekers, not DevOps engineers - complexity must be hidden behind simple interfaces.

**Implications:**
- All services defined in docker-compose.yml with proper dependencies
- Environment variables with sensible defaults
- Automatic database initialization and schema migration
- Health checks and service readiness probes

### 3.5 Workflow-Driven Architecture

**Description:** Complex multi-step processes are orchestrated through n8n workflows rather than tightly coupled code.

**Rationale:** Enables visual workflow management, easier debugging, and allows non-technical users to understand and modify processes.

### 3.6 Resilient-by-Default

**Description:** System must gracefully handle external service failures, rate limits, and network issues without losing data or requiring manual intervention.

**Rationale:** Job boards frequently change, APIs go down, and networks are unreliable - system must continue operating.

### 3.7 Performance Within Constraints

**Description:** Optimize for the 8GB RAM constraint while meeting performance targets for scraping and AI processing.

### 3.8 Observable Operations

**Description:** Provide comprehensive visibility into system health, job processing status, and performance metrics through dashboards and logs.

---

## 4. Component Architecture

### 4.1 Monorepo Structure (WESPA-Style)

The system uses a pnpm workspaces monorepo with apps/ and packages/@jobsearch/ directories:

```
pa-assistant/
├── pnpm-workspace.yaml           # pnpm workspaces config
├── package.json                  # Root workspace config
├── tsconfig.json                 # Shared TypeScript config (strict mode)
├── docker-compose.yml            # Container orchestration
│
├── apps/
│   ├── api-server/               # Express API + job orchestration
│   ├── job-crawler/              # Playwright-based scrapers
│   ├── web-ui/                   # React SPA frontend
│   └── n8n-workflows/            # Workflow automation definitions
│
└── packages/@jobsearch/
    ├── types/                    # Shared TypeScript types
    ├── database/                 # Prisma + PostgreSQL
    ├── config/                   # Zod-validated configuration
    ├── logger/                   # Pino structured logging
    ├── ai-client/                # LiteLLM wrapper for Ollama/Claude
    └── common/                   # Shared utilities
```

### 4.2 Architecture Diagram

```
┌─────────────────┐
│   Web UI (5173) │  apps/web-ui
└─────────┬───────┘
          │
┌─────────▼───────┐
│  API Server     │  apps/api-server
│  (Express/3000) │
└─────────┬───────┘
          │
┌─────────▼───────────────────────────────┐
│ Internal Services Network (docker)      │
│ ┌─────────────┐ ┌─────────────────────┐ │
│ │ job-crawler │ │ n8n-workflows       │ │
│ │ (Playwright)│ │ (automation)        │ │
│ └─────────────┘ └─────────────────────┘ │
│ ┌─────────────┐ ┌─────────────────────┐ │
│ │ LiteLLM     │ │ Ollama              │ │
│ │ (AI proxy)  │ │ (7B local model)    │ │
│ └─────────────┘ └─────────────────────┘ │
└─────────────────────────────────────────┘
          │
┌─────────▼───────────────────────────────┐
│ Data Layer                              │
│ ┌─────────────┐ ┌─────────────────────┐ │
│ │PostgreSQL 16│ │Redis 7 + Volumes    │ │
│ └─────────────┘ └─────────────────────┘ │
└─────────────────────────────────────────┘
```

### 4.3 Applications (apps/)

| Application | Purpose | Location | Dependencies |
|-------------|---------|----------|--------------|
| **api-server** | Express API with job orchestration and real-time communication | `apps/api-server` | @jobsearch/types, database, config, logger, ai-client |
| **job-crawler** | Playwright-based job scrapers with stealth capabilities | `apps/job-crawler` | @jobsearch/types, logger, common |
| **web-ui** | React SPA with offline support and PWA capabilities | `apps/web-ui` | @jobsearch/types |
| **n8n-workflows** | Workflow automation definitions and orchestration | `apps/n8n-workflows` | n8n |

### 4.4 Shared Packages (packages/@jobsearch/)

| Package | Purpose | Location | Dependencies |
|---------|---------|----------|--------------|
| **@jobsearch/types** | Shared TypeScript type definitions | `packages/@jobsearch/types` | None |
| **@jobsearch/database** | Prisma client and repositories | `packages/@jobsearch/database` | @jobsearch/types |
| **@jobsearch/config** | Zod-validated configuration | `packages/@jobsearch/config` | None |
| **@jobsearch/logger** | Pino structured logging | `packages/@jobsearch/logger` | None |
| **@jobsearch/ai-client** | LiteLLM wrapper for Ollama/Claude | `packages/@jobsearch/ai-client` | @jobsearch/types, config |
| **@jobsearch/common** | Shared utilities and error handling | `packages/@jobsearch/common` | @jobsearch/types |

### 4.5 Package Dependency Flow

```
apps → packages/@jobsearch/* → external dependencies

Rules:
- Packages cannot depend on apps
- Packages can depend on other packages
- Apps import packages via workspace protocol
```

---

## 5. Data Architecture

### 5.1 Data Stores

| Store | Technology | Purpose | Scaling Strategy |
|-------|------------|---------|------------------|
| **Primary Database** | PostgreSQL 15 | Jobs, applications, user profiles, analytics | Vertical scaling with connection pooling |
| **Cache Layer** | Redis 7 | Sessions, match scores, dashboard data | Single instance with TTL management |
| **File Storage** | Docker Volumes | CV uploads, generated documents, backups | Local disk with cleanup policies |

### 5.2 Core Entities

#### Job
```
- id: UUID (PK)
- title: VARCHAR(255)
- company: VARCHAR(255)
- description: TEXT
- requirements: JSONB
- source_platform: VARCHAR(50)
- external_id: VARCHAR(255)
- scraped_at: TIMESTAMP
- processed_at: TIMESTAMP
```

#### UserProfile
```
- id: UUID (PK)
- email: VARCHAR(255)
- skills: JSONB
- preferences: JSONB
- cv_data: JSONB
- created_at: TIMESTAMP
- updated_at: TIMESTAMP
```

#### Application
```
- id: UUID (PK)
- job_id: UUID (FK)
- user_id: UUID (FK)
- status: VARCHAR(50) [Saved, Reviewing, Applied, Interviewing, Rejected, Offered]
- notes: TEXT
- applied_at: TIMESTAMP
- status_updated_at: TIMESTAMP
```

#### MatchScore
```
- id: UUID (PK)
- job_id: UUID (FK)
- user_id: UUID (FK)
- overall_score: DECIMAL(3,2) [0-1]
- skill_match: DECIMAL(3,2)
- experience_match: DECIMAL(3,2)
- calculated_at: TIMESTAMP
```

#### GeneratedContent
```
- id: UUID (PK)
- application_id: UUID (FK)
- user_id: UUID (FK)
- content_type: VARCHAR(50) [cover_letter, tailored_cv]
- content: TEXT
- version: INTEGER
- generated_at: TIMESTAMP
```

### 5.3 Data Retention Policy

| Data Type | Retention | Notes |
|-----------|-----------|-------|
| Jobs | 6 months after scraping | Unsaved jobs cleaned up |
| Applications | Indefinite | User-controlled |
| Match scores | 30 days | Recalculated on demand |
| Analytics events | 1 year | Aggregated data retained longer |
| Generated content | Indefinite | With versioning |
| Session data | 1 hour TTL | Redis auto-expiry |

---

## 6. Integration Architecture

### 6.1 API Design

- **Pattern:** REST
- **URL Structure:** `/api/v1/{service}/{resource}`
- **Versioning:** URL path versioning
- **Response Format:** JSON envelope with `data`, `meta`, and `error` fields

### 6.2 Integration Contracts

| System | Protocol | Authentication | Circuit Breaker | Retry Policy |
|--------|----------|----------------|-----------------|--------------|
| RemoteOK API | REST | API key in headers | 5 failures / 300s reset | 3 attempts, exponential 2000ms |
| Claude API | REST | Bearer token | 3 failures / 60s reset | 2 attempts, exponential 1000ms |
| Ollama Local LLM | REST | None (local) | 5 failures / 30s reset | 2 attempts, fixed 1000ms |
| Email (SMTP/IMAP) | SMTP/IMAP | Username/password | 3 failures / 120s reset | 3 attempts, linear 5000ms |
| Google Drive (rclone) | REST | OAuth2 | 3 failures / 300s reset | 3 attempts, exponential 5000ms |
| n8n Workflow Engine | REST | API key / webhook | 5 failures / 60s reset | 2 attempts, fixed 2000ms |

### 6.3 Event-Driven Architecture

**Event Bus:** Internal event system with Socket.io for real-time client updates

**Event Types:**
- `job.scraped`
- `job.processed`
- `match.calculated`
- `application.status_changed`
- `content.generated`
- `backup.completed`
- `workflow.triggered`
- `user.profile_updated`

---

## 7. Security Architecture

### 7.1 Security Boundaries

```
Internet → [API Gateway] → [Services] → [Data Layer]
  ↑           ↑              ↑           ↑
Untrusted   Auth/Rate    Internal    Encrypted
 Zone       Limiting      Zone        Storage
```

**Zones:**
1. **External Zone** - Untrusted internet and external APIs
2. **Gateway Zone** - API Gateway with rate limiting and authentication
3. **Application Zone** - Internal services with service-to-service communication
4. **Data Zone** - PostgreSQL and Redis with encrypted storage

### 7.2 Authentication & Authorization

| Aspect | Implementation |
|--------|----------------|
| **Authentication** | **Local-trust model** - No user authentication required |
| **Description** | Single-user local deployment trusts localhost connections |
| **Internal Tokens** | Service-to-service uses environment-based shared secrets |
| **Authorization** | RBAC with `user` and `system` roles for internal services |

> **Note:** This is a single-user local deployment. There is no user login/registration. The system trusts all localhost connections. Internal service communication uses shared secrets via environment variables.

### 7.3 Security Controls

| Control | Implementation | Location |
|---------|----------------|----------|
| Input Validation | Express.js middleware with Joi schema | API Gateway |
| Rate Limiting | Express rate limiter with Redis (100 req/min/IP) | API Gateway |
| Data Encryption at Rest | PostgreSQL TDE, encrypted Docker volumes | Data Layer |
| Data Encryption in Transit | TLS 1.3 for all HTTP communications | Network |
| API Key Management | Environment variables, Docker secrets | All services |
| Session Security | Redis session storage, secure cookies, CSRF | Web UI |
| Anti-Detection | Playwright stealth, fingerprint randomization | Scraping Service |
| Audit Logging | Structured logging with rotation (30 days) | All services |
| Backup Encryption | rclone encryption with user-controlled keys | Backup Service |

### 7.4 Sensitive Data Handling

| Data Type | Classification | Handling |
|-----------|----------------|----------|
| PII | PII | Encrypted at rest, masked in logs, local storage only |
| CV/Resume Data | Confidential | Encrypted storage, version tracking, secure deletion |
| API Keys | Confidential | Environment variables only, never logged |
| LinkedIn Sessions | Internal | Redis with TTL, encrypted cookies |
| Application Data | Internal | Encrypted database, user-controlled retention |

### 7.5 Compliance

- **GDPR:** Local-first data architecture, user data sovereignty

---

## 8. Deployment Architecture

### 8.1 Target Environment

- **Platform:** Docker Compose
- **Topology:** Single-host containerized deployment
- **External Access:** API Gateway on port 3000 only

### 8.2 Environment Variables

| Variable | Description | Sensitive |
|----------|-------------|-----------|
| `JWT_SECRET` | Secret key for JWT token signing | Yes |
| `DATABASE_URL` | PostgreSQL connection string | Yes |
| `REDIS_URL` | Redis connection string | Yes |
| `CLAUDE_API_KEY` | Anthropic Claude API key | Yes |
| `ENCRYPTION_KEY` | AES-256 key for data at rest | Yes |
| `BACKUP_ENCRYPTION_KEY` | Key for backup encryption | Yes |
| `NODE_ENV` | Application environment | No |
| `LOG_LEVEL` | Logging verbosity | No |

### 8.3 Resource Requirements (WESPA-Style Services)

| Component | CPU Request | CPU Limit | Memory Request | Memory Limit |
|-----------|-------------|-----------|----------------|--------------|
| api-server | 100m | 500m | 128Mi | 256Mi |
| job-crawler | 250m | 1000m | 512Mi | 1.5Gi |
| web-ui | 50m | 200m | 64Mi | 128Mi |
| n8n | 200m | 500m | 256Mi | 512Mi |
| PostgreSQL | 250m | 1000m | 512Mi | 1Gi |
| Redis | 100m | 500m | 128Mi | 256Mi |
| Ollama | 500m | 2000m | 2Gi | 4Gi |
| LiteLLM | 100m | 500m | 128Mi | 256Mi |

### 8.4 Memory Budget (8GB Total)

| Component | Allocation | Description |
|-----------|------------|-------------|
| **Ollama** | 4GB | 7B quantized model |
| **PostgreSQL** | 1GB | Main database |
| **job-crawler** | 1.5GB | Chromium instance |
| **n8n** | 512MB | Workflow engine |
| **Redis** | 256MB | Job queue + cache |
| **api-server** | 256MB | Express API |
| **LiteLLM** | 256MB | LLM proxy |
| **web-ui** | 128MB | Nginx + static |

**Monitoring:**
- Warning threshold: 80%
- Critical threshold: 90%
- Action at critical: Auto-unload Ollama model

### 8.5 Containerization

- **Base Image:** node:24-alpine
- **Build Strategy:** Multi-stage with separate build and runtime stages

---

## 9. Operational Concerns

### 9.1 Health Checks

| Endpoint | Purpose | Checks |
|----------|---------|--------|
| `/health/ready` | Readiness check | Database, Redis, external APIs |
| `/health/live` | Liveness check | Service responsiveness, memory usage |
| `/health/startup` | Startup check | Database migrations, initial data load |

### 9.2 Logging

- **Destination:** stdout with structured JSON format
- **Retention:** 30 days via Docker log rotation

**Key Events:**
- `job_scraping_started/completed`
- `ai_matching_performed`
- `content_generation_requested`
- `authentication_failed`
- `rate_limit_exceeded`
- `system_error`

### 9.3 Metrics

| Metric | Type | Alert Threshold |
|--------|------|-----------------|
| `job_scraping_duration_seconds` | histogram | > 900s |
| `ai_matching_processing_time_seconds` | histogram | > 10s |
| `content_generation_duration_seconds` | histogram | > 90s |
| `database_connection_pool_usage` | gauge | > 90% |
| `memory_usage_bytes` | gauge | > 80% limit |
| `api_requests_total` | counter | Error rate > 5% |
| `jobs_processed_total` | counter | No jobs in 24h |

### 9.4 Feature Flags

- `LINKEDIN_SCRAPING_ENABLED`
- `CLAUDE_AI_ENABLED`
- `LOCAL_AI_FALLBACK`
- `BACKUP_AUTO_SYNC`
- `EMAIL_NOTIFICATIONS`

---

## 10. Architectural Decisions

### ADR-001: Containerized Modular Monolith Architecture

**Status:** Accepted

**Context:** Need to balance deployment simplicity for single-user setup with maintainability and component isolation.

**Decision:** Implement containerized modular monolith with Docker Compose orchestration.

**Rationale:** Provides the right balance of modularity and simplicity for single-user deployment. Enables service isolation without microservices complexity.

### ADR-002: PostgreSQL as Primary Database with JSONB Extensions

**Status:** Accepted

**Decision:** Use PostgreSQL 15 with JSONB extensions and time-series capabilities.

**Rationale:** Provides ACID guarantees for critical data while offering flexible JSON storage for varying job data formats.

### ADR-003: Local-First Data Architecture with Optional Cloud Backup

**Status:** Accepted

**Decision:** Implement local-first data architecture with encrypted optional cloud backup.

**Rationale:** Ensures zero infrastructure costs and complete privacy compliance while providing user-controlled backup options.

### ADR-004: Hybrid AI Strategy with Local-First Processing

**Status:** Accepted

**Decision:** Implement hybrid AI with local Ollama for matching and Claude API for content generation.

**Rationale:** Keeps sensitive job matching data local while using high-quality cloud AI for content generation where privacy is less critical.

### ADR-005: Docker Compose for Single-Host Deployment

**Status:** Accepted

**Decision:** Use Docker Compose for all deployment scenarios.

**Rationale:** Perfect fit for single-user deployment with minimal operational complexity.

### ADR-006: JWT Authentication with Local Session Management

**Status:** Accepted

**Decision:** Implement JWT authentication with Redis-backed session management.

**Rationale:** Provides stateless authentication suitable for service communication while maintaining local control.

### ADR-007: Event-Driven Architecture with Redis Pub/Sub

**Status:** Accepted

**Decision:** Use Redis Pub/Sub for event-driven communication with WebSocket for real-time UI updates.

**Rationale:** Leverages existing Redis infrastructure to provide loose coupling and real-time capabilities.

### ADR-008: OpenTelemetry with Local Jaeger for Observability

**Status:** Accepted

**Decision:** Implement OpenTelemetry with local Jaeger instance for distributed tracing.

**Rationale:** Provides comprehensive observability without external dependencies or costs.

### ADR-009: pnpm Workspaces for Monorepo

**Status:** Accepted

**Context:** Need to manage multiple TypeScript packages and services in a monorepo structure while maintaining simplicity for single-user deployment and avoiding complex build orchestration tools.

**Options Considered:**
| Option | Pros | Cons |
|--------|------|------|
| npm Workspaces | Built into npm, simple | Limited features, slower installs |
| pnpm + Turborepo | Fast, advanced caching | Additional complexity, overkill for single-user |
| **pnpm Only** | Fast installs, efficient disk usage, simple | No build orchestration |

**Decision:** Use pnpm workspaces without Turborepo for monorepo management.

**Rationale:** Provides efficient package management and workspace support without the complexity of build orchestration tools. Perfect balance for single-user deployment while maintaining development efficiency.

**Consequences:**
- Single pnpm workspace root
- Shared dependencies across packages
- Fast, efficient installs
- Simple build scripts

### ADR-010: Memory Budget Allocation

**Status:** Accepted

**Context:** Need to ensure the system operates within 8GB memory constraint while providing optimal performance for AI processing, job scraping, and data storage.

**Options Considered:**
| Option | Pros | Cons |
|--------|------|------|
| Dynamic Allocation | Flexible, optimal utilization | Complex, unpredictable |
| Equal Distribution | Simple, fair | Inefficient, doesn't match workload |
| **Fixed Budget + Monitoring** | Predictable, prevents OOM | Less flexible |

**Decision:** Implement fixed memory budget allocation with automated monitoring and Ollama model unloading.

**Rationale:** Ensures predictable memory usage within 8GB constraint while allocating resources based on actual service needs. Ollama gets largest allocation (4GB) as the most memory-intensive component.

**Consequences:**
- Fixed memory limits per service
- Automated memory monitoring at 80%/90% thresholds
- Ollama model auto-unloading at critical threshold
- Clear resource boundaries for Docker Compose

---

## 11. Multi-Agent Review Summary

This TAD was reviewed by three AI agents: Claude (direct analysis), Codex (architectural review), and Gemini (gap analysis and research).

### 11.1 Claude Analysis

#### Strengths
- **Comprehensive Coverage:** 57 requirements mapped to 297 user stories with 1,406 acceptance criteria
- **Well-Defined Principles:** 8 architecture principles provide clear guidance for implementation
- **Privacy-First Design:** Strong data sovereignty with local-only storage by default
- **Resilience Patterns:** Circuit breakers, retry logic, and graceful degradation built into core design
- **Detailed Component Breakdown:** Clear service boundaries with defined responsibilities

#### Concerns
- **Complexity vs. Simplicity Trade-off:** "Modular monolith" label may understate the actual microservice-like complexity
- **Authentication Contradiction:** Privacy-by-Design states "no authentication required" (line 1843) but Security Architecture defines full JWT/RBAC (line 3107-3108)
- **Resource Budget Gaps:** Ollama and n8n not included in resource requirements table - critical for 8GB constraint
- **Legal Risk Unmitigated:** LinkedIn stealth scraping with explicit ToS violation lacks legal safeguards

### 11.2 Codex Architectural Review

#### Strengths
- **Privacy-First Design:** Local-only data storage with Docker containerization provides strong data isolation and zero cloud costs
- **Hybrid AI Strategy:** Smart balance between Ollama (local, unlimited) and Claude API (optional, budget-limited) for cost control
- **Resilience Patterns:** Circuit breakers, exponential backoff, and health checks show maturity in handling external service failures
- **Workflow Orchestration:** n8n-based automation provides visual debugging and reduces code complexity
- **Comprehensive Disaster Recovery:** Multi-layered backup strategy (local, cloud, automated verification) with restore scripts

#### Concerns
- **8GB RAM Viability:** Running Ollama 7B + PostgreSQL + Redis + n8n + Playwright (headed mode) + Web frontend simultaneously will likely exceed 8GB under load. Ollama alone typically requires 4-6GB for 7B models
- **LinkedIn Legal Risk:** Stealth scraping with fingerprint randomization, canvas manipulation, and anti-detection explicitly violates LinkedIn ToS. "Legal Compliance" principle contradicts implementation
- **Performance Bottleneck:** Match scoring requires 10s/job with batch processing 300 jobs in 50min. If daily scraping yields >300 jobs, queue will grow indefinitely
- **Monolith Complexity:** "Modular monolith" with 57 requirements and 297 user stories will create tight coupling. No clear module boundaries defined
- **Single Point of Failure:** n8n orchestrates critical workflows but has no redundancy strategy if it fails during scraping

#### Recommendations
1. **Memory Budget Analysis:** Create detailed RAM allocation table (Ollama 4GB, PostgreSQL 1GB, etc.) and load test with realistic data. Consider Ollama model quantization (Q4) or swap to lighter models
2. **Legal Posture Clarification:** Either remove LinkedIn stealth scraping or explicitly document legal risks with user disclaimers. Consider LinkedIn email alerts + API as compliant alternatives
3. **Scalability Design:** Add job queue priority system (high-match jobs processed first) and make batch size configurable based on available RAM
4. **Architecture Decision Records:** Document trade-offs for monolith vs microservices, especially around LinkedIn scraper isolation
5. **Failure Mode Testing:** Define degraded operation modes (e.g., system works without LinkedIn, without AI, without email) and test recovery paths

#### Overall Assessment
**Architecture is 70% production-ready** with strong foundations in privacy, resilience, and disaster recovery. Critical blockers are RAM constraints and LinkedIn legal risk.

### 11.3 Gemini Gap Analysis (from Stories Review)

#### Missing User Stories
| ID | Domain | Title | Why Needed |
|----|--------|-------|------------|
| NEW-001 | LinkedIn | Handle LinkedIn 2FA/OTP Challenges | If LinkedIn asks for SMS/Email code, automation fails |
| NEW-002 | Offline | View Dashboard Offline | Users should browse saved jobs without connection |
| NEW-003 | Offline | Queue Actions Offline | Actions should queue and sync when online |
| NEW-004 | Data | Detect & Archive "Zombie Jobs" | Jobs often close within days; need health check |
| NEW-005 | Security | Sanitize Job Description HTML | Stored XSS risk from scraped HTML |
| NEW-006 | UX | Warm-up Mode for New Accounts | New LinkedIn accounts need gradual ramping |

#### Acceptance Criteria Gaps
- **US-210 (LinkedIn Login):** Needs AC for 2FA prompt handling
- **US-180 (Docker Deploy):** Needs AC for non-root container user
- **US-016 (Deduplication):** Needs AC for reposted job handling

#### Security Considerations
- Run containers as non-root users (User 1000)
- Encrypt local backup files before cloud sync
- Add cost velocity circuit breaker for Claude API

#### Scraping Edge Cases
- "Easy Apply" detection to auto-update status
- Salary nuances ("competitive", "DOE") handling
- Remote restrictions ("US Residents Only") parsing

#### LinkedIn-Specific Scenarios
- Session "Death" Loop prevention (disable after 3 failed logins)
- CAPTCHA handling with user notification

### 11.4 Consolidated Recommendations

| Priority | Recommendation | Risk Addressed | Status |
|----------|----------------|----------------|--------|
| **P0** | Create detailed memory budget for 8GB constraint | System may not start | ✅ **RESOLVED** (ADR-010, Section 8.4) |
| **P0** | Resolve auth contradiction (JWT vs no-auth) | Implementation confusion | ✅ **RESOLVED** (Section 7.2: local-trust) |
| **P0** | Define legal posture for LinkedIn scraping | Legal liability | ✅ **RESOLVED** (REQ-059: consent required) |
| **P1** | Add 2FA/CAPTCHA handling for LinkedIn | Scraping failures | Pending |
| **P1** | Include Ollama/n8n in resource requirements | Resource exhaustion | ✅ **RESOLVED** (Section 8.3, 8.4) |
| **P1** | Add HTML sanitization for job descriptions | XSS vulnerability | Pending |
| **P2** | Implement offline support stories | Poor UX | Pending |
| **P2** | Add zombie job detection | Stale data | Pending |
| **P2** | Define degraded operation modes | Partial failures | Pending |

### 11.5 Production Readiness Assessment

| Category | Score | Notes |
|----------|-------|-------|
| Architecture Design | 8/10 | Comprehensive but complex |
| Security | 7/10 | Good controls but auth contradiction |
| Privacy | 9/10 | Strong local-first design |
| Resilience | 8/10 | Circuit breakers and retry logic |
| Observability | 8/10 | OpenTelemetry + metrics + logging |
| Scalability | 5/10 | 8GB constraint not fully addressed |
| Legal Compliance | 4/10 | LinkedIn ToS violation risk |
| Documentation | 9/10 | Extensive ADRs and specifications |

**Overall Score: 72% Production-Ready**

**Recommended Next Steps:**
1. Address P0 blockers before implementation
2. Consider MVP with LinkedIn email parsing only (zero risk)
3. Add stealth scraping as opt-in feature with explicit disclaimers
4. Load test on 8GB system before finalizing resource allocations

---

## Appendix A: Requirements Traceability

This TAD addresses the following requirement categories:

- **Job Discovery:** REQ-001 through REQ-005, REQ-041 through REQ-047
- **Intelligent Matching:** REQ-006 through REQ-010
- **Content Generation:** REQ-011 through REQ-014
- **Application Tracking:** REQ-015 through REQ-018
- **User Interface:** REQ-019 through REQ-021
- **Analytics:** REQ-022 through REQ-024
- **Automation:** REQ-025 through REQ-026
- **System Reliability:** REQ-027 through REQ-032
- **Infrastructure:** REQ-049
- **Disaster Recovery:** REQ-050 through REQ-057
- **Non-Functional:** REQ-033 through REQ-040

## Appendix B: Cross-Cutting Concerns

| Concern | Related Requirements | Related ACs |
|---------|---------------------|-------------|
| Audit Logging | REQ-030 | AC-803 to AC-808 |
| Rate Limiting | REQ-001, REQ-027, REQ-043, REQ-047 | AC-003, AC-031, AC-739, AC-1032, AC-1152 |
| Data Validation | REQ-002, REQ-004, REQ-006, REQ-047 | AC-036, AC-102, AC-165, AC-1149 |
| Performance Monitoring | REQ-034 to REQ-037 | AC-890, AC-902, AC-914, AC-920 |
| Backup/Recovery | REQ-031, REQ-048, REQ-052, REQ-057 | AC-822, AC-1174, AC-1254, AC-1387 |
| Security/Privacy | REQ-038, REQ-039, REQ-042, REQ-045 | AC-932, AC-952, AC-1016, AC-1088 |
| Notifications | REQ-017, REQ-023, REQ-024, REQ-056 | AC-463, AC-647, AC-665, AC-1356 |

---

*Generated from TAD-001.json v1.0.2 with multi-agent review on 2026-02-08*
*Updated with WESPA-style monorepo architecture and P0 blocker resolutions*
